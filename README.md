# chat-localhost-llama3
develop for localhost to connect local llama3 model provide by ollama. this is personal project