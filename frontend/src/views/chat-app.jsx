// Sound feedback for user and AI
const chimes = typeof window !== "undefined" ? new window.Audio("/sounds/bell-1.mp3") : null;
const bellSound =
  typeof window !== 'undefined' ? new window.Audio('/sounds/bell-1.mp3') : null;

// =============================
// TODO: FUTURE PRODUCTION UPGRADE
// - For production, consider using server-based STT/TTS for consistent, high-quality voice features.
// - Add REST endpoints in backend: /api/stt and /api/tts
// - Add Docker services for TTS (e.g., coqui-ai/tts, mozilla-tts) and STT (e.g., whisper, kaldi, deepgram)
// - Modularize frontend to allow switching between browser and server STT/TTS
// - Add a toggle in UI for "Browser" vs "Server" voice mode
// =============================
import { useContext, useEffect, useRef, useState } from "react";
// --- Inline STT/TTS for full voice mode loop ---
// (No longer using STTButton/TTSButton for main loop)
import MonacoEditorWrapper from "../components/MonacoEditorWrapper";
import ReactMarkdown from "react-markdown";
import remarkGfm from "remark-gfm";
import rehypeHighlight from "rehype-highlight";
import Loader from "../components/loader";
import STTButton from "../components/STTButton";
import { AppSetting } from "./App-setting";




function CopyableCodeBlock({ children, className = '', ...props }) {
  const text = Array.isArray(children) ? children.join("") : children;
  const [isCopied, setIsCopied] = useState(false);
  const [isEditing, setIsEditing] = useState(false);
  const [editValue, setEditValue] = useState(text);
  const [ariaMsg, setAriaMsg] = useState("");
  let lang = '';
  if (className && className.startsWith('language-')) {
    lang = className.replace('language-', '');
  }
  return (
    <div style={{ position: "relative", marginBottom: 16 }}>
      <div style={{
        display: 'flex',
        alignItems: 'center',
        justifyContent: 'space-between',
        background: '#f5f7fa',
        borderTopLeftRadius: 6,
        borderTopRightRadius: 6,
        border: '1px solid #e0e0e0',
        borderBottom: 'none',
        padding: '0.3rem 0.8rem',
        fontSize: '0.97rem',
        fontFamily: 'monospace',
        color: '#4f8cff',
      }}>
        <span style={{ fontWeight: 600 }}>{lang || 'code'}</span>
        <span>
          <button
            type="button"
            aria-label="Copy code"
            style={{
              background: isCopied ? "#4f8cff" : "#fff",
              color: isCopied ? "#fff" : "#4f8cff",
              border: "1px solid #4f8cff",
              borderRadius: 6,
              padding: "2px 10px",
              fontSize: "0.95rem",
              cursor: "pointer",
              marginRight: 8,
              transition: "all 0.2s",
            }}
            onClick={async () => {
              try {
                await navigator.clipboard.writeText(text);
                setIsCopied(true);
                setTimeout(() => setIsCopied(false), 1200);
                if (setScreenReaderMessage) setScreenReaderMessage("Code copied to clipboard");
              } catch {}
            }}
          >
            {isCopied ? "Copied!" : "Copy"}
          </button>
          <button
            type="button"
            aria-label="Edit code"
            style={{
              background: isEditing ? "#4f8cff" : "#fff",
              color: isEditing ? "#fff" : "#4f8cff",
              border: "1px solid #4f8cff",
              borderRadius: 6,
              padding: "2px 10px",
              fontSize: "0.95rem",
              cursor: "pointer",
              transition: "all 0.2s",
            }}
            onClick={() => {
              setIsEditing(true);
              if (setScreenReaderMessage) setScreenReaderMessage("Code editor opened");
            }}
            disabled={isEditing}
          >
            Edit
          </button>
        </span>
      </div>
      {isEditing ? (
        <MonacoEditorWrapper
          value={editValue}
          language={lang}
          onChange={v => setEditValue(v)}
          onCancel={() => setIsEditing(false)}
          onSave={() => { setIsEditing(false); }}
        />
      ) : (
        <pre
          {...props}
          style={{
            backgroundColor: "#f0f0f0",
            padding: 12,
            borderBottomLeftRadius: 6,
            borderBottomRightRadius: 6,
            border: '1px solid #e0e0e0',
            borderTop: 'none',
            overflowX: "auto",
            fontFamily: "monospace",
            margin: 0,
          }}
        >
          <code>{text}</code>
        </pre>
      )}
    </div>
  );
}


// Helper: Render a file/code block with filename heading
function FileCodeBlock({ filename, code, language }) {
  return (
    <div style={{ marginBottom: 24 }}>
      {filename && (
        <div style={{
          background: '#f5f7fa',
          borderTopLeftRadius: 6,
          borderTopRightRadius: 6,
          border: '1px solid #e0e0e0',
          borderBottom: 'none',
          padding: '0.3rem 0.8rem',
          fontSize: '0.97rem',
          fontFamily: 'monospace',
          color: '#4f8cff',
          fontWeight: 600,
        }}>{filename}</div>
      )}
      <CopyableCodeBlock className={language ? `language-${language}` : ''}>{code}</CopyableCodeBlock>
    </div>
  );
}


// Recursively render any AI response as readable blocks (code, files, markdown, text)
// Improved MarkdownRenderer: adds line breaks and restores copy/edit for all code blocks
function MarkdownRenderer({ content }) {
  function renderAny(val, keyPrefix = '', isTopLevel = true) {
    if (typeof val === 'string') {
      // Split summary/explanation from code blocks for clarity
      const parts = val.split(/(```[\s\S]*?```)/g);
      return (
        <div key={keyPrefix}>
          {parts.map((part, idx) => {
            if (part.startsWith('```')) {
              // Extract language and code
              const match = part.match(/^```(\w+)?\n([\s\S]*?)```$/);
              const lang = match ? match[1] || '' : '';
              const code = match ? match[2] : part.replace(/^```|```$/g, '');
              return (
                <div key={idx} style={{ margin: '16px 0' }}>
                  <CopyableCodeBlock className={lang ? `language-${lang}` : ''}>{code}</CopyableCodeBlock>
                </div>
              );
            } else if (part.trim()) {
              // Summary/explanation: add margin below
              return <div key={idx} style={{ marginBottom: 12 }}><ReactMarkdown remarkPlugins={[remarkGfm]} rehypePlugins={[rehypeHighlight]}>{part}</ReactMarkdown></div>;
            } else {
              return null;
            }
          })}
        </div>
      );
    }
    if (Array.isArray(val)) {
      return val.map((item, idx) => renderAny(item, keyPrefix + '-' + idx, false));
    }
    if (val && typeof val === 'object') {
      // If object looks like a file/code block
      const filename = val.filename || val.name || val.file || '';
      const code = val.code || val.content || val.text || '';
      const language = val.language || val.lang || '';
      if (filename && code) {
        return <div key={keyPrefix + filename} style={{ margin: '16px 0' }}><FileCodeBlock filename={filename} code={code} language={language} /></div>;
      }
      // If object has multiple keys, render each
      return Object.entries(val).map(([k, v], idx) => (
        <div key={keyPrefix + '-' + k}>
          {filename || language ? null : <strong>{k}:</strong>}
          {renderAny(v, keyPrefix + '-' + k, false)}
        </div>
      ));
    }
    return null;
  }
  return <>{renderAny(content)}</>;
}

const ChatApp = () => {
  // --- Voice Mode ---
  // Now: Full browser-based voice mode loop (auto listen, send, TTS, repeat)
  const [voiceMode, setVoiceMode] = useState(false);
  const [listening, setListening] = useState(false);
  const recognitionRef = useRef(null);
  // Helper: Start browser STT and auto-send to AI
  const startVoiceRecognition = () => {
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    if (!SpeechRecognition) {
      setScreenReaderMessage("Speech Recognition is not supported in this browser.");
      alert("Speech Recognition is not supported in this browser. Please use Google Chrome or Microsoft Edge.");
      return;
    }
    try {
      const recognition = new SpeechRecognition();
      recognition.continuous = false;
      recognition.interimResults = false;
      recognition.lang = "en-US";
      recognition.onresult = (event) => {
        const transcript = event.results[0][0].transcript;
        setInput("");
        setListening(false);
        setScreenReaderMessage("You said: " + transcript);
        // Auto-send to AI
        handleSend(transcript);
      };
      recognition.onerror = (e) => {
        setListening(false);
        setScreenReaderMessage("Speech recognition error");
        if (e.error === 'not-allowed') {
          alert('Microphone access denied. Please allow microphone permissions.');
        }
      };
      recognition.onend = () => setListening(false);
      recognitionRef.current = recognition;
      setListening(true);
      recognition.start();
    } catch (err) {
      setListening(false);
      setScreenReaderMessage('Speech Recognition failed to start.');
    }
  };

  // Helper: Speak text using browser TTS
  const speakText = (text, onEnd) => {
    if (!window.speechSynthesis || !window.SpeechSynthesisUtterance) {
      setScreenReaderMessage('Text-to-Speech is not supported in this browser.');
      alert('Text-to-Speech is not supported in this browser. Please use Google Chrome or Microsoft Edge.');
      if (onEnd) onEnd();
      return;
    }
    try {
      const utterance = new window.SpeechSynthesisUtterance(text);
      utterance.onend = () => { if (onEnd) onEnd(); };
      utterance.onerror = () => { if (onEnd) onEnd(); };
      window.speechSynthesis.speak(utterance);
    } catch (err) {
      if (onEnd) onEnd();
    }
  };
  const { currentModel, apiUrl, isStream, mode, temperature, maxTokens, systemTemplate, user: contextUser } = useContext(AppSetting);
  const [input, setInput] = useState("");
  const [messages, setMessages] = useState([]);
  const [loading, setLoading] = useState(false);
  const [error, setError] = useState(null);
  const [context, setContext] = useState([]);
  const [responseTime, setResponseTime] = useState(null);
  const [screenReaderMessage, setScreenReaderMessage] = useState("");
  const [conversations, setConversations] = useState([]);
  const [currentConvId, setCurrentConvId] = useState(null);
  const [sidebarOpen, setSidebarOpen] = useState(true);
  const [convLoading, setConvLoading] = useState(false);
  const [userLocation, setUserLocation] = useState(null);
  const liveRegionRef = useRef(null);
  const lastAssistantMsgRef = useRef(null);
  const endOfMessagesRef = useRef(null);
  const errorRef = useRef(null);
  const systemRef = useRef(null);
  const [user, setUser] = useState(contextUser || localStorage.getItem("user") || "");
  
  // Get user location on mount
  useEffect(() => {
    if (navigator.geolocation) {
      navigator.geolocation.getCurrentPosition(
        async (position) => {
          const { latitude, longitude } = position.coords;
          
          // Try to get city name from reverse geocoding (using free API)
          try {
            const response = await fetch(
              `https://api.bigdatacloud.net/data/reverse-geocode-client?latitude=${latitude}&longitude=${longitude}&localityLanguage=en`
            );
            const data = await response.json();
            
            setUserLocation({
              city: data.city || data.locality || 'Unknown',
              country: data.countryName || 'Unknown',
              latitude,
              longitude,
            });
            
            console.log('üìç User location detected:', data.city, data.countryName);
          } catch (err) {
            // Fallback to just coordinates
            setUserLocation({
              latitude,
              longitude,
            });
            console.log('üìç User location detected (coords only):', latitude, longitude);
          }
        },
        (error) => {
          console.log('‚ùå Location access denied or unavailable:', error.message);
        },
        { enableHighAccuracy: false, timeout: 10000 }
      );
    }
  }, []);
  
  // Fetch conversation list on mount (if logged in)
  useEffect(() => {
    if (!user || !user._id) return;
    fetchConversations();
  }, [user]);

  // Fetch conversations
  const fetchConversations = async () => {
    setConvLoading(true);
    try {
      const res = await fetch(`${apiUrl.replace(/\/$/, "")}/conversations`, { credentials: 'include' });
      const json = await res.json();
      if (json?.success) setConversations(json.conversations || []);
    } catch {}
    setConvLoading(false);
  };

  // Load a conversation by id
  const loadConversation = async (id) => {
    setLoading(true);
    setCurrentConvId(id);
    try {
      const res = await fetch(`${apiUrl.replace(/\/$/, "")}/conversations/${id}`, { credentials: 'include' });
      const json = await res.json();
      if (json?.success) {
        setMessages(json.conversation.messages.map(m => ({ role: m.sender === 'user' ? 'user' : 'assistant', content: m.text })));
      }
    } catch {}
    setLoading(false);
  };

  // Start a new conversation
  const handleNewChat = async () => {
    setInput("");
    setMessages([]);
    setCurrentConvId(null);
  };

  useEffect(() => {
    endOfMessagesRef.current?.scrollIntoView({ behavior: "smooth" });
    // Announce new assistant message for screen readers
    if (messages.length > 0 && messages[messages.length - 1].role === "assistant") {
  setScreenReaderMessage("Assistant: " + messages[messages.length - 1].content.replace(/\s+/g, " ").slice(0, 200));
  // Announce response is ready
  setTimeout(() => setScreenReaderMessage("AI response is ready."), 500);
      // Focus the last assistant message
      lastAssistantMsgRef.current?.focus();
    }
  }, [messages]);

  useEffect(() => {
    if (systemRef.current) {
      systemRef.current.focus();
    }
  }, [systemTemplate]);

  // Announce loading and response time for screen readers
  useEffect(() => {
    if (loading) {
      setScreenReaderMessage("Loading response...");
    }
  }, [loading]);
  useEffect(() => {
    if (responseTime) {
      setScreenReaderMessage(`Response time: ${responseTime} milliseconds`);
    }
  }, [responseTime]);

  useEffect(() => {
    if (errorRef.current) {
      errorRef.current.focus();
    }
  }, [error]);

  // Overload handleSend: accepts optional text (for voice mode), else uses input
  const handleSend = async (textOverride) => {
    const textToSend = typeof textOverride === 'string' ? textOverride : input;
    // Play bell sound for user action (processing)
    try { if (chimes) { chimes.currentTime = 0; chimes.play(); } } catch {}
    if (!textToSend.trim()) return;
    setLoading(true);
    setError(null);
    const start = Date.now();
    const newMessage = { role: "user", content: textToSend };
    let updatedMessages = [...messages, newMessage];
    setMessages(updatedMessages);
    setInput("");
    
    try {
      // Route to correct endpoint based on mode
      const isChatMode = mode === "chat";
      const endpoint = apiUrl
        ? apiUrl.replace(/\/$/, "") + (isChatMode ? "/api/chat" : "/api/generate")
        : (isChatMode ? "/api/chat" : "/api/generate");
      
      // Build request body based on mode
      let requestBody;
      if (isChatMode) {
        // Chat mode: send full conversation history with system message
        const allMessages = systemTemplate 
          ? [{ role: "system", content: systemTemplate }, ...updatedMessages]
          : updatedMessages;
        requestBody = {
          model: currentModel,
          messages: allMessages,
          stream: !!isStream,
          temperature,
          max_tokens: maxTokens,
          userLocation, // Include user location for context-aware responses
        };
      } else {
        // Generate mode: traditional prompt-based
        requestBody = {
          model: currentModel,
          prompt: textToSend,
          stream: !!isStream,
          context,
          system: systemTemplate || undefined,
          temperature,
          max_tokens: maxTokens,
          userLocation, // Include user location for generate mode too
        };
      }
      
      const response = await fetch(endpoint, {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify(requestBody),
      });
      if (!response.ok) throw new Error(`HTTP error! status: ${response.status}`);
      let result = "";
      if (isStream) {
        const reader = response.body.getReader();
        const decoder = new TextDecoder();
        let done = false;
        let buffer = "";
        while (!done) {
          const { done: streamDone, value } = await reader.read();
          done = streamDone;
          if (value) {
            buffer += decoder.decode(value, { stream: true });
          }
        }
        // Parse streaming response
        try {
          const parsed = JSON.parse(buffer);
          // Handle both chat and generate streaming formats
          result = parsed.message?.content || parsed.response || buffer;
        } catch {
          result = buffer;
        }
      } else {
        // Non-streaming response
        const text = await response.text();
        try {
          const parsed = JSON.parse(text);
          // Handle both chat and generate response formats
          result = parsed.message?.content || parsed.response || text;
        } catch {
          result = text;
        }
      }
      // Recursively extract all string content from result
      function extractStrings(val) {
        if (typeof val === 'string') return val;
        if (Array.isArray(val)) return val.map(extractStrings).join('\n');
        if (val && typeof val === 'object') {
          // Prefer 'text', 'content', or join all string values
          if (val.text) return extractStrings(val.text);
          if (val.content) return extractStrings(val.content);
          return Object.values(val).map(extractStrings).join('\n');
        }
        return '';
      }
      const aiContent = extractStrings(result);
      updatedMessages = [...updatedMessages, { role: "assistant", content: aiContent }];
      setMessages(updatedMessages);
      setResponseTime(Date.now() - start);
      // Play bell sound for AI response
      try { if (chimes) { chimes.currentTime = 0; chimes.play(); } } catch {}

      // Speak AI response if in voice mode
      if (voiceMode && aiContent) {
        speakText(aiContent, () => {
          // After TTS, auto-listen again
          if (voiceMode) startVoiceRecognition();
        });
      }

      // Save or update conversation in backend
      if (user && user._id) {
        if (!currentConvId) {
          // Create new conversation
          const convRes = await fetch(`${apiUrl.replace(/\/$/, "")}/conversations`, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            credentials: 'include',
            body: JSON.stringify({
              title: updatedMessages[0]?.content?.slice(0, 30) || 'New chat',
              messages: updatedMessages.map(m => ({ sender: m.role === 'user' ? 'user' : 'assistant', text: m.content })),
            }),
          });
          const convJson = await convRes.json();
          if (convJson?.success) {
            setCurrentConvId(convJson.conversation._id);
            fetchConversations();
          }
        } else {
          // Update existing conversation
          await fetch(`${apiUrl.replace(/\/$/, "")}/conversations/${currentConvId}`, {
            method: 'PUT',
            headers: { 'Content-Type': 'application/json' },
            credentials: 'include',
            body: JSON.stringify({
              messages: updatedMessages.map(m => ({ sender: m.role === 'user' ? 'user' : 'assistant', text: m.content })),
            }),
          });
          fetchConversations();
        }
      }
    } catch (err) {
      setError(err.message);
    } finally {
      setLoading(false);
    }
  };

  // Start/stop voice mode effect
  useEffect(() => {
    if (voiceMode) {
      // Start listening automatically
      startVoiceRecognition();
    } else {
      // Stop any ongoing recognition
      if (recognitionRef.current) {
        recognitionRef.current.stop();
      }
      setListening(false);
    }
    // eslint-disable-next-line react-hooks/exhaustive-deps
  }, [voiceMode]);

  return (
    <div style={{ display: 'flex', height: '100%' }}>
      {/* Sidebar for conversation history */}
      <aside style={{ width: sidebarOpen ? 240 : 0, transition: 'width 0.2s', background: '#f4f6fa', borderRight: '1px solid #e0e0e0', overflow: 'auto', minHeight: '100%' }}>
        <div style={{ padding: '1rem', borderBottom: '1px solid #e0e0e0', display: 'flex', alignItems: 'center', justifyContent: 'space-between' }}>
          <span style={{ fontWeight: 700, fontSize: '1.1rem' }}>Conversations</span>
          <button onClick={handleNewChat} style={{ background: '#4f8cff', color: '#fff', border: 'none', borderRadius: 6, padding: '0.3rem 0.8rem', fontWeight: 600, cursor: 'pointer' }}>+ New Chat</button>
        </div>
        {convLoading ? <div style={{ padding: '1rem' }}>Loading...</div> : null}
        <ul style={{ listStyle: 'none', margin: 0, padding: 0 }}>
          {conversations.map(conv => (
            <li key={conv._id} style={{ borderBottom: '1px solid #e0e0e0', background: conv._id === currentConvId ? '#e6f0ff' : 'transparent' }}>
              <button
                style={{ width: '100%', textAlign: 'left', background: 'none', border: 'none', padding: '0.8rem 1rem', fontSize: '1rem', cursor: 'pointer', fontWeight: conv._id === currentConvId ? 700 : 400 }}
                onClick={() => loadConversation(conv._id)}
                aria-current={conv._id === currentConvId ? 'true' : undefined}
              >
                {conv.title || 'Untitled'}
                <div style={{ fontSize: '0.85rem', color: '#888', marginTop: 2 }}>{new Date(conv.updatedAt).toLocaleString()}</div>
              </button>
            </li>
          ))}
        </ul>
      </aside>
      {/* Main chat area */}
      <div className="chat-app-container" style={{ flex: 1, minWidth: 0 }}>
        {/* Screen reader live region for new messages, errors, loading, and response time */}
        <div
          ref={liveRegionRef}
          aria-live="polite"
          aria-atomic="true"
          style={{ position: "absolute", left: "-9999px", height: 1, width: 1, overflow: "hidden" }}
        >
          {screenReaderMessage}
        </div>
        
        {/* No Model Warning */}
        {!currentModel && (
          <div style={{
            background: "#fff3cd",
            border: "1px solid #ffc107",
            borderRadius: 8,
            padding: "0.75rem 1rem",
            margin: "1rem",
            display: "flex",
            alignItems: "center",
            gap: "0.75rem"
          }}>
            <span style={{ fontSize: "1.5rem" }}>‚ö†Ô∏è</span>
            <div style={{ flex: 1 }}>
              <strong style={{ color: "#856404" }}>No Model Selected</strong>
              <div style={{ fontSize: "0.875rem", color: "#555", marginTop: "0.25rem" }}>
                Please select an AI model from the header dropdown before chatting.
              </div>
            </div>
          </div>
        )}

        {/* Mode Info Banner */}
        <div style={{
          background: mode === "chat" ? "#e3f2fd" : "#e8f5e9",
          border: `1px solid ${mode === "chat" ? "#2196f3" : "#4caf50"}`,
          borderRadius: 8,
          padding: "0.75rem 1rem",
          margin: "1rem",
          display: "flex",
          alignItems: "center",
          gap: "0.75rem"
        }}>
          <span style={{ fontSize: "1.5rem" }}>{mode === "chat" ? "üí¨" : "üìù"}</span>
          <div style={{ flex: 1 }}>
            <strong style={{ color: mode === "chat" ? "#1976d2" : "#388e3c" }}>
              {mode === "chat" ? "Chat Mode" : "Generate Mode"}
            </strong>
            <div style={{ fontSize: "0.875rem", color: "#555", marginTop: "0.25rem" }}>
              {mode === "chat" 
                ? `Quick conversational responses ‚Ä¢ Temp: ${temperature} ‚Ä¢ Max: ${maxTokens} tokens ‚Ä¢ Full conversation history`
                : `Detailed, long-form content ‚Ä¢ Temp: ${temperature} ‚Ä¢ Max: ${maxTokens} tokens ‚Ä¢ Creative generation`
              }
            </div>
          </div>
        </div>

        <div className="messages-list">
          {messages.map((msg, idx) => (
            <div
              key={idx}
              className={`message message-${msg.role}`}
              tabIndex={msg.role === "assistant" ? 0 : -1}
              ref={msg.role === "assistant" && idx === messages.length - 1 ? lastAssistantMsgRef : null}
              aria-label={msg.role === "assistant" ? `Assistant: ${msg.content.replace(/\s+/g, " ").slice(0, 200)}` : undefined}
            >
              {msg.role === "user" ? (
                <h5 className="message-heading" style={{ fontSize: '1.05rem', margin: 0, fontWeight: 700 }}>
                  You
                </h5>
              ) : (
                <h6 className="message-heading" style={{ fontSize: '1.02rem', margin: 0, fontWeight: 700 }}>
                  AI
                </h6>
              )}
              <div className="message-content">
                <MarkdownRenderer content={msg.content} />
              </div>
            </div>
          ))}
          <div ref={endOfMessagesRef} />
        </div>
        {error && (
          <div
            ref={errorRef}
            tabIndex={-1}
            className="error-message"
            aria-live="assertive"
            aria-atomic="true"
          >
            {error}
          </div>
        )}
        <form
          className="input-area"
          onSubmit={e => { e.preventDefault(); handleSend(); }}
          role="search"
          aria-label="Chat input area"
        >
          <label htmlFor="chat-input" className="visually-hidden">Type your message</label>
          <textarea
            id="chat-input"
            value={input}
            onChange={e => setInput(e.target.value)}
            placeholder="Type your message..."
            rows={2}
            aria-label="Type your message"
            onKeyDown={e => {
              if (e.key === 'Enter' && !e.shiftKey) {
                e.preventDefault();
                handleSend();
              }
            }}
          />
          {/* Voice mode: show status and manual STT only if not in voice mode */}
          {!voiceMode && (
            <STTButton
              onResult={text => setInput(text)}
              disabled={loading}
            />
          )}
          {voiceMode && (
            <span style={{ marginRight: 8, fontWeight: 600, color: listening ? '#4f8cff' : '#888' }}>
              {listening ? 'üé§ Listening...' : 'üõë Paused'}
            </span>
          )}
          <button
            type="button"
            aria-label={voiceMode ? "Disable voice mode" : "Enable voice mode"}
            style={{ marginRight: 8, background: voiceMode ? '#4f8cff' : '#fff', color: voiceMode ? '#fff' : '#4f8cff', border: '1px solid #4f8cff', borderRadius: 6, padding: '2px 10px', fontWeight: 600, cursor: 'pointer' }}
            onClick={() => setVoiceMode(v => !v)}
          >{voiceMode ? 'üîä Voice On' : 'üîá Voice Off'}</button>
          <button
            type="submit"
            disabled={loading || !input.trim() || !currentModel}
            aria-label="Send message"
            title={!currentModel ? "Please select a model first" : "Send message"}
          >
            Send
          </button>
                {/* Removed misplaced TTSButton. It is rendered per message below. */}
        </form>
        {/* Accessible spinner and live announcement for AI processing */}
        {loading && (
          <div
            role="status"
            aria-live="assertive"
            aria-atomic="true"
            style={{ display: 'flex', alignItems: 'center', gap: 12, margin: '1rem 0' }}
          >
            <span id="ai-processing-announcement" style={{ fontWeight: 700, color: '#1976d2' }}>
              Andhru AI is working. Please wait while your personal assistant processes your request...
            </span>
            <Loader />
          </div>
        )}
        {responseTime && (
          <div className="response-time" aria-live="polite">Response time: {responseTime} ms. AI response is ready.</div>
        )}
      </div>
    </div>
  );
};

export default ChatApp;
